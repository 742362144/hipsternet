# hipsternet
All the hipster things in Neural Net in a single repo: hipster optimization algorithms, hispter regularizations, everything!

Note, things will be added over time, so not all the hipsterest things will be here immediately. Also don't use this for your production code: use this to study and learn new things in the realm of Neural Net, Deep Net, Deep Learning, whatever.

## What's in it?

#### Optimization algorithms

1. SGD
2. Momentum SGD
3. Nesterov Momentum
4. Adagrad
5. RMSprop
6. Adam

#### Loss functions

1. Cross Entropy
2. Hinge Loss

#### Regularization

1. Dropout
2. Your usual L1 and L2 regularization

#### Hipster techniques

1. BatchNorm
2. Xavier weight initialization


## How to run this?

1. Install miniconda <http://conda.pydata.org/miniconda.html>
2. Do `conda env create`
3. Enter the env `source activate hipsternet`
3. Do things with the code if you want to
4. Run `python run.py`
5. Just close the terminal if you done (or `source deactivate`, not a fan though)

## What can I do with this?

Do anything you want. I licensed this with Unlicense License <http://unlicense.org>, as I need to take a break of using WTFPL license.
